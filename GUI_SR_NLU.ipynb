{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91926d14",
   "metadata": {},
   "source": [
    "# Graphical User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab5d77",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13c39d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import resampy\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bfb6b",
   "metadata": {},
   "source": [
    "Animation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08b4d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animation(count):\n",
    "    global anim\n",
    "    im2 = im[count]\n",
    "\n",
    "    gif_label.configure(image=im2)\n",
    "    count += 1\n",
    "    if count == frames:\n",
    "        count = 0\n",
    "    anim = root.after(50,lambda :animation(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910aebf7",
   "metadata": {},
   "source": [
    "Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc1eab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio):\n",
    "    new_model=load_model('E:/Speech_recognition/SpeechRecogModel.keras')\n",
    "    prob=new_model.predict(audio.reshape(1,8000,1))\n",
    "    index=np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d9566",
   "metadata": {},
   "source": [
    "Reading Voice Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "556ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_text():\n",
    "    \n",
    "    count = 0\n",
    "    anim = None\n",
    "    animation(count)\n",
    "    samplerate = 16000  \n",
    "    duration = 1 # seconds\n",
    "    filename = 'yes.wav'\n",
    "    print(\"start\")\n",
    "    mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,channels=1, blocking=True)\n",
    "    print(\"end\")\n",
    "    sd.wait()\n",
    "    sf.write(filename, mydata, samplerate)\n",
    "\n",
    "    filepath = 'C:/Users/vinnu'\n",
    "    samples, sample_rate = librosa.load(filepath + '/' + 'yes.wav', sr = 16000)\n",
    "    samples = librosa.resample(samples, orig_sr=sample_rate, target_sr=8000)\n",
    "    ipd.Audio(samples,rate=8000)\n",
    "    \n",
    "    T = tk.Text(root, height=2, width=30, bg=\"black\", fg=\"azure\")\n",
    "    T.pack()\n",
    "    T.insert(tk.END, \"Did you said : \" + predict(samples))\n",
    " \n",
    "\n",
    "    print(predict(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f2526",
   "metadata": {},
   "source": [
    "Creating list of PhotoImage objects for each frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "44caaeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "off\n",
      "start\n",
      "end\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "off\n",
      "start\n",
      "end\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "off\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "file=\"E:/Speech_recognition/Voice2.gif\"\n",
    "\n",
    "info = Image.open(file)\n",
    "\n",
    "frames = 80  # gives total number of frames that gif contains\n",
    "im = [tk.PhotoImage(file=file,format=f\"gif -index {i}\") for i in range(frames)]\n",
    "\n",
    "classes = ['down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
    "\n",
    "gif_label = tk.Label(root,image=\"\")\n",
    "gif_label.pack()\n",
    "\n",
    "start = tk.Button(root,text=\"start\",bg=\"black\", fg=\"azure\",command=record_text)\n",
    "start.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0a361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13e1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
